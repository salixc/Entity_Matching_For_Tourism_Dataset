{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 591\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sentence_transformers.util import cos_sim  \n",
    "from sentence_transformers import SentenceTransformer as SBert\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "from numpy import sqrt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import trange\n",
    "# modelName = 'princeton-nlp/sup-simcse-bert-base-uncased'\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "dataName1 = \"Mafengwo\"\n",
    "dataName2 = \"Tripadvisor\"\n",
    "\n",
    "with open(\"../user_data/%s_addr.json\"%dataName1, \"r\", encoding=\"utf-8\") as f:\n",
    "    data1 = json.load(f)\n",
    "with open(\"../user_data/%s_addr.json\"%dataName2, \"r\", encoding=\"utf-8\") as f:\n",
    "    data2 = json.load(f)\n",
    "print(len(data1), len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53, 17, 6, 18, 30, 1, 10, 4, 1, 5, 8, 7, 16, 28, 5, 5, 0, 25, 20]\n",
      "[109, 29, 22, 25, 56, 20, 9, 14, 10, 14, 12, 15, 15, 21, 21, 16, 14, 17, 152]\n"
     ]
    }
   ],
   "source": [
    "# with open(\"../user_data/香港十八区.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     districtSet = json.load(f)\n",
    "\n",
    "# stat1 = [0 for _ in range(19)]\n",
    "# stat2 = [0 for _ in range(19)]\n",
    "# for d in data1:\n",
    "#     dist = d[\"行政区\"]\n",
    "#     if dist in districtSet:\n",
    "#         stat1[districtSet.index(dist)] += 1\n",
    "#     else:\n",
    "#         stat1[-1] += 1\n",
    "# for d in data2:\n",
    "#     dist = d[\"行政区\"]\n",
    "#     if dist in districtSet:\n",
    "#         stat2[districtSet.index(dist)] += 1\n",
    "#     else:\n",
    "#         stat2[-1] += 1\n",
    "# print(stat1)\n",
    "# print(stat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48428\n"
     ]
    }
   ],
   "source": [
    "with open(\"../user_data/districtList.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    districtSet = json.load(f)\n",
    "\n",
    "def combineEnt(d1, d2, district):\n",
    "    rnt = {\"id\": \"%s-%s\"%(d1[\"id\"], d2[\"id\"])}\n",
    "    rnt[\"行政区\"] = district\n",
    "    for attr in list(d1.keys())[2:]:\n",
    "        rnt[attr] = [d1[attr], d2[attr]]\n",
    "    return rnt\n",
    "\n",
    "result = []\n",
    "for d1 in data1:\n",
    "    if d1[\"行政区\"] not in districtSet and d1[\"行政区\"] != \"U\":\n",
    "        continue\n",
    "    for d2 in data2:\n",
    "        if d2[\"行政区\"] not in districtSet and d2[\"行政区\"] != \"U\":\n",
    "            continue\n",
    "        # 任意一个实体的行政区未知，则进行匹配\n",
    "        if d1[\"行政区\"] == \"U\" or d2[\"行政区\"] == \"U\":\n",
    "            result.append(combineEnt(d1, d2, \"U\"))\n",
    "        # 两个实体的行政区一致，也进行匹配\n",
    "        elif d1[\"行政区\"] == d2[\"行政区\"]:\n",
    "            result.append(combineEnt(d1, d2, d1[\"行政区\"]))\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 850/850 [00:26<00:00, 32.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Do word vector calculations on all occurrences of strings in advance\n",
    "# to reduce the time complexity of subsequent processes\n",
    "if os.path.exists(\"pre_dict.json\"):\n",
    "    print(\"Preprocessing dictionary file already exists!\")\n",
    "else:\n",
    "    eDict = {}\n",
    "    cols = [\"Name\", \"Address\", \"District\", \"RoadInfo\", \"Poi\", \"RoomInfo\"]\n",
    "    data = data1 + data2\n",
    "    for i in trange(len(data)):\n",
    "        d = data[i]\n",
    "        for col in cols:\n",
    "            target = d[col]\n",
    "            if target == None or target == \"\": continue\n",
    "            if target not in eDict:\n",
    "                eDict[target] = model.encode(target).tolist()\n",
    "    with open(\"pre_dict.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(eDict, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48428/48428 [00:10<00:00, 4518.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "with open(\"pre_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    eDict = json.load(f)\n",
    "\n",
    "def calcDist(pos1, pos2):\n",
    "    if pos1[0] is None or pos2[0] is None:\n",
    "        return None\n",
    "    return geodesic((pos1[1], pos1[0]), (pos2[1], pos2[0])).kilometers\n",
    "\n",
    "def calcSimi(lst1, lst2):\n",
    "    lstCosine = []\n",
    "    for i in range(len(lst1)):\n",
    "        if lst1[i] == \"\" or lst2[i] == \"\":\n",
    "            lstCosine.append(None)\n",
    "        else:\n",
    "            e1 = eDict[lst1[i]]\n",
    "            e2 = eDict[lst2[i]]\n",
    "            sim = 1 - cosine(e1, e2)\n",
    "            lstCosine.append(sim)\n",
    "    return lstCosine\n",
    "\n",
    "cols = [\"id\", \"行政区\", \"Location\", \"Name\", \"Address\", \"District\", \"RoadInfo\", \"Poi\", \"RoomInfo\"]\n",
    "dfList = []\n",
    "cnt = 0\n",
    "for i in trange(len(result)):\n",
    "    d = result[i]\n",
    "    lst = [d[\"id\"], d[\"行政区\"]]\n",
    "    lst.append(calcDist(d[\"Location\"][0], d[\"Location\"][1]))\n",
    "    lst1 = [d[attr][0] for attr in cols[3:]]\n",
    "    lst2 = [d[attr][1] for attr in cols[3:]]\n",
    "    lst = lst + calcSimi(lst1, lst2)\n",
    "    dfList.append(lst)\n",
    "df = pd.DataFrame(dfList, columns=cols)\n",
    "df = df.fillna(value=np.nan)\n",
    "df.to_csv(\"../user_data/data.csv\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e8f95b9510f32b9cde8cca11ac739448e236da4e8c1197f2e248ca6ab198849"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
